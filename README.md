# CapsStARE: Casule-based Spatiotemporal Architecture for Robust and Efficient Gaze Estimation

https://github.com/user-attachments/assets/b40557ce-3e4e-430a-bae2-310dd96884e5

**CapStARE** is a capsule-based spatiotemporal model for gaze estimation. By combining capsule networks, attention mechanisms, and lightweight temporal decoders, CapStARE achieves state-of-the-art performance across multiple benchmarks while maintaining real-time efficiency. 

## ðŸ”¥ Key Features
- **Capsule-based spatial encoding** for robust handling of gaze under extreme head poses.
- **Dual-path GRU decoders** for temoral modeling of head and eye dynamics.
- **Lightweight design:** real-time inference at ~8ms per frame.
- **Generalizable**: validated across ETH-XGaze, MPIIfaceGaze, Gaze360, and RT-GENE.
- **Practical**: tested in real-time webcam video scenarios for human-robot interaction and unconstrained use cases.

## Benchmark Performance


